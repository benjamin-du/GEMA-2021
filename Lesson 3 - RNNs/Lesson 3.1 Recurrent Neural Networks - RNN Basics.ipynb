{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align: center; color: lightblue; font-size: 40px'> RNN and LSTM </h1>\n",
    "<h2 style='text-align: center; color: lightblue; font-size: 30px'> RNN </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The idea of recurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\"> source </a>\n",
    "\n",
    "<p style=\"font-size:120%\">A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://karpathy.github.io/assets/rnn/diags.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:120%\">The important idea of RNN is that the output is calculated using not only the input, but also the previous state of the hidden layer ! But this previous state was influenced by the previous input (and past previous states, which were influenced by past inputs, and so on...) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The core equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the class, we saw the equation for a linear regression. What is the equation for a RNN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    #...\n",
    "    def step(self, x):\n",
    "        # update the hidden state\n",
    "        self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))\n",
    "        # compute the output vector\n",
    "        y = np.dot(self.W_hy, self.h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "* self.h: the hidden <i> state </i>, initiliazed with the zero vector\n",
    "* W_hh, W_xh, W_hy: <i> parameters </i> to be learned through backprop\n",
    "* * W_xh : turns the one-hot encoded input vector into embeddings of size vocab-size, size vocab_size * num_hidden\n",
    "* * W_hh : size num_hidden * num_hidden \n",
    "* * W_hy : size num_hidden * vocab_size\n",
    "* np.dot(): matrix multiplication (nowadays performed with @ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: LSTM has just a more complex self.h = ... equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But what is self.h ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/700/1*NKhwsOYNUT5xU7Pyf6Znhg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a vector which contains information about what happened before. It encodes the context of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass it as input to the next calculation, as well as the Xt+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if the sentence is \"My coach is a good man\", for the last prediction, we pass \"good\" to the model, as well as a vector h that contains the context for \"My coach is a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello: RNN from scratch ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not this time: instead we will deconstruct code from <a href=\"https://medium.com/@mliuzzolino/hello-rnn-55a9237b7112\"> this article </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "        \n",
    "        characters = np.sort(list(set(string)))\n",
    "        self.num_characters = len(characters)\n",
    "        \n",
    "        self.char_to_idx = { ch : i for i, ch in enumerate(characters) }\n",
    "        self.idx_to_char = { i : ch for ch, i in self.char_to_idx.items() }\n",
    "        \n",
    "        self._process()\n",
    "        \n",
    "    def _process(self):\n",
    "        data_torch = torch.tensor([self.make_onehot(ele).data.numpy() for ele in self.string])\n",
    "\n",
    "        self.X = data_torch[:-1].float()\n",
    "        self.y = torch.argmax(data_torch[1:], dim=1).long()\n",
    "        \n",
    "    def make_onehot(self, char):\n",
    "        return torch.eye(self.num_characters)[self.char_to_idx[char]].float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  deconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE: for each Q below, print some code and add a commentary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Hello!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: in the above code, find the line where we get the different unique characters of our string and sort them\n",
    "\n",
    "\n",
    "# Q: How many different characters do we have ? \n",
    "\n",
    "\n",
    "# Q: how does np.sort orders punctuation compared to letters ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does char_to_idx and idx_to_char do ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To emphrasize the ordering of punctuation, print the idx of the character \"!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _make_onehot\n",
    "<code>make_onehot (takes \"char\" as an argument): \n",
    "return torch.eye(self.num_characters)[self.char_to_idx[char]].float()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q: first, what does torch.eye(n) do ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, what does char_to_idx[char] do ? \n",
    "\n",
    "# finally, what does the complete line torch.eye(self.num_characters)[char_to_idx[char]] do ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process\n",
    "<code>def _process(self):\n",
    "    data_torch = torch.tensor([self.make_onehot(ele).data.numpy() for ele in self.string])\n",
    "    self.X = data_torch[:-1].float()\n",
    "    self.y = torch.argmax(data_torch[1:], dim=1).long()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# data_torch = torch.tensor([self.make_onehot(ele).data.numpy() for ele in self.string])\n",
    "# put the list comprehension inside torch.tensor as a classic for loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 1., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0.]),\n",
       " tensor([0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 1., 0.]),\n",
       " tensor([0., 0., 0., 0., 1.]),\n",
       " tensor([1., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list comprehensions:\n",
    "[torch.eye(5)[char_to_idx[ele]] for ele in string]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Why .data.numpy() ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([torch.eye(5).numpy()]) # try removing the .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will work\n",
    "torch.tensor([torch.tensor(1), torch.tensor(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7b43593c7c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# but this won't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# but this won't \n",
    "torch.tensor([torch.tensor([1, 2]), torch.tensor([2, 2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a111c3304a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# doesn't work;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# doesn't work; \n",
    "print(type([torch.eye(5)[char_to_idx[ele]] for ele in string][0]))\n",
    "torch.tensor([torch.eye(5)[char_to_idx[ele]] for ele in string])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway: when you see this error, remember to use .data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '?', 'a', 'l']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the end, the line:\n",
    "# torch.tensor([torch.eye(5)[char_to_idx[ele]].data.numpy() for ele in string])\n",
    "# just gives back a one-hot encoded tensor for each character in the string\n",
    "# the last tensor has a \"one\" in the first position, because \"!\" has value 0 in the\n",
    "# char_to_idx dictionnary, and it has value 0 it the char_to_idx dictionnary because\n",
    "sorted('l?a!')\n",
    "# sorted() sorts puctuation before letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up the data using our DataHandler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DataHandler class with the Hello! string to create your data\n",
    "data = DataHandler(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we've seen, make one_hot gives you your input vector\n",
    "data.make_onehot('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is all your data: \n",
    "data.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 3, 4, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the labels associated: \n",
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0.]) tensor(2)\n",
      "tensor([0., 0., 1., 0., 0.]) tensor(3)\n",
      "tensor([0., 0., 0., 1., 0.]) tensor(3)\n",
      "tensor([0., 0., 0., 1., 0.]) tensor(4)\n",
      "tensor([0., 0., 0., 0., 1.]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# use a loop to print each data point with its associated label:\n",
    "# For example, when we pass \"H\" to the model, we want it to predict 2 ( parce que data.idx_to_char[2] = e)\n",
    "# hint: I used zip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deconstruct RNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, num_chars, num_hidden):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_chars = num_chars\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        # Network Parameters\n",
    "        # Potential Input\n",
    "        self.Wxh = nn.Parameter(torch.randn((num_chars, num_hidden)))\n",
    "        self.Whh = nn.Parameter(torch.randn((num_hidden, num_hidden)))\n",
    "        self.bh = nn.Parameter(torch.zeros((num_hidden)))\n",
    "        \n",
    "        # Hidden -> Output\n",
    "        self.Why = nn.Parameter(torch.randn((num_hidden, num_chars)))\n",
    "        self.by = nn.Parameter(torch.zeros((num_chars))) \n",
    "        \n",
    "        # Activations\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def init(self):\n",
    "        # Initialize hidden state to zero\n",
    "        self.h = torch.zeros((self.num_hidden))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # here is the \"model\", the equation presented above\n",
    "        self.h = self.tanh((x @ self.Wxh) + (self.h @ self.Whh + self.bh))\n",
    "        y_output = self.h @ self.Why + self.by\n",
    "        return y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just like a fully connected neural net, you pick your number of hidden neurons\n",
    "num_hidden = 60\n",
    "num_chars = data.num_characters\n",
    "\n",
    "Wxh = torch.randn((num_chars, num_hidden))\n",
    "Wxh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "# now you can start plugging the numbers:\n",
    "result1 = data.X[0] @ Wxh\n",
    "print(result1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state shape: torch.Size([60])\n",
      "Whh shape: torch.Size([60, 60])\n",
      "bh shape: torch.Size([60])\n",
      "We output a vector of size num_hidden\n",
      "torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "# deconstructing this line: self.h = self.tanh((x @ self.Wxh) + (self.h @ self.Whh + self.bh))\n",
    "h = torch.zeros((num_hidden))\n",
    "Whh = torch.randn((num_hidden, num_hidden))\n",
    "bh = torch.zeros(num_hidden)\n",
    "print(\"hidden state shape: \" + str(h.shape))\n",
    "print(\"Whh shape: \" + str(Whh.shape))\n",
    "print(\"bh shape: \" + str(bh.shape))\n",
    "result2 = h @ Whh + bh\n",
    "print(\"We output a vector of size num_hidden\")\n",
    "print(result2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see, hidden state for next input is indeed the same as initial hidden state shape\n",
    "nn.Tanh()(result1+result2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7424,  1.3627, -0.4633, -0.8275,  1.1662])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deconstructing this line: y_output = self.h @ self.Why + self.by\n",
    "Why = torch.randn((num_hidden, num_chars))\n",
    "bh = torch.randn(num_chars)\n",
    "print((h @ Why + bh).shape)\n",
    "h @ Why + bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "my_rnn_cell = RNNCell(5, 50)\n",
    "print(isinstance(my_rnn_cell, nn.Module))\n",
    "print(hasattr(nn.Module, \"parameters\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 50])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# Classes: what happens is when you subclass nn.Module, \n",
    "# it will register for you every time you add a nn.parameter:\n",
    "\n",
    "for param in my_rnn_cell.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> note that self.h is NOT a parameter. It's the state of the cell. It's not updated directly by backprop </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deconstruct HelloRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelloRNN(nn.Module):    \n",
    "    def __init__(self, num_chars, num_hidden=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cell = RNNCell(num_chars, num_hidden)       \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for param in self.cell.parameters():  # this is just what we did above\n",
    "            param.requires_grad_(True)  # not necessary here but a good practice\n",
    "            \n",
    "            if param.data.ndimension() >= 2:\n",
    "                # we won't go into much detail for this\n",
    "                # just remember that if we set our parameters for a\n",
    "                # linear regression to bad numbers it can ruin the\n",
    "                # training. Xavier Glorot has come up with some good ideas\n",
    "                # to find good numbers to start with\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            else:\n",
    "                # self.bh and self.by are just biases, they can be initially set to 0\n",
    "                nn.init.zeros_(param.data)\n",
    "                \n",
    "    def forward(self, X):\n",
    "        # Setup outputs container\n",
    "        outputs = torch.zeros_like(X)\n",
    "        \n",
    "        # Iterate through sequence\n",
    "        self.cell.init()\n",
    "        for i, x in enumerate(X):\n",
    "            # this takes one line of X i.e [0., 1., 0., 0., 0.]\n",
    "            # representing the h. And asks for an output of size ...? \n",
    "            outputs[i] = self.cell(x)\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    # we won't analyze generate into too much detail, but you are free to do this at home :-)\n",
    "    def generate(self, data, init_char, num_steps=5):\n",
    "        # Check for valid character\n",
    "        if init_char not in data.char_to_idx:\n",
    "            avail_chars = \",\".join(data.char_to_idx.keys())\n",
    "            print(f\"Character not in vocab. Pick another from: {avail_chars}\")\n",
    "            return\n",
    "\n",
    "        self.eval()\n",
    "\n",
    "        # Setup feed\n",
    "        feed = torch.zeros((num_steps, data.num_characters))\n",
    "        feed[0] = data.make_onehot(init_char).unsqueeze(dim=0)\n",
    "\n",
    "        output = [init_char]\n",
    "        for predict_i in range(num_steps-1):\n",
    "            feed_in = feed[:predict_i+1]\n",
    "            next_chars = self(feed_in)[-1]\n",
    "            \n",
    "            next_char_idx = torch.argmax(next_chars).item()\n",
    "            next_char = data.idx_to_char[next_char_idx]\n",
    "\n",
    "            feed[predict_i+1] = data.make_onehot(next_char).unsqueeze(dim=0)\n",
    "            output.append(next_char)\n",
    "\n",
    "        output_str = \"\".join(output)\n",
    "        return output_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our class to define a network\n",
    "net = HelloRNN(num_chars=data.num_characters, num_hidden=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we saw this morning and last week what an optimiser does\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# store the losses (just to plot a graph)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/5000 -- Loss: 1.8737 -- Network out: H!l!H!\n",
      "\r",
      "Epoch 11/5000 -- Loss: 1.3098 -- Network out: H!lll!\n",
      "\r",
      "Epoch 21/5000 -- Loss: 0.9096 -- Network out: H!llo!\n",
      "\r",
      "Epoch 31/5000 -- Loss: 0.6387 -- Network out: H!llo!\n",
      "\r",
      "Epoch 41/5000 -- Loss: 0.4683 -- Network out: Hello!\n",
      "\n",
      "Ending early. Converged in 40 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe76d245550>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_EPOCHS = 5000\n",
    "LR = 0.005\n",
    "end_early = False\n",
    "seq_i = \"\"\n",
    "\n",
    "net.train() # Ensure net in training mode\n",
    "for epoch_i in range(N_EPOCHS):\n",
    "    # Zero out gradients\n",
    "    optimizer.___________\n",
    "    \n",
    "    # Get net output, calculate loss, and generate gradients\n",
    "    output = ___(______)\n",
    "    loss = criterion(______, ____._)\n",
    "    \n",
    "    # This is where the magic happens\n",
    "    loss.__________ # Generate gradients via autodiff\n",
    "    \n",
    "    # Step\n",
    "    # -----------------------------------\n",
    "    # Clip params\n",
    "    for param in net.parameters():\n",
    "        if param.grad is None:\n",
    "            continue\n",
    "        grad_val = torch.clamp(param.grad, -5, 5)\n",
    "    optimizer.______\n",
    "    # some people put the optimizer.zero_grad() here\n",
    "    # -----------------------------------\n",
    "    \n",
    "    # Track loss\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Qualitative Eval\n",
    "    if epoch_i % 10 == 0:\n",
    "        seq_i = net.generate(data, data.string[0], num_steps=len(data.string))\n",
    "        \n",
    "        if seq_i == data.string:\n",
    "            end_early = True\n",
    "            \n",
    "        # Stdout\n",
    "        # --------------------------------\n",
    "        print(f'\\rEpoch {epoch_i+1}/{N_EPOCHS} -- Loss: {losses[-1]:0.4f} -- Network out: {seq_i}')\n",
    "    \n",
    "    if end_early:\n",
    "        print(f\"\\nEnding early. Converged in {epoch_i} epochs.\")\n",
    "        break\n",
    "    \n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a \"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_char = data.string[0]\n",
    "net.generate(data, init_char, num_steps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNN and LSTM are the same thing. The second just has a more complicated equation\n",
    "* what is powerful with RNN: they don't have a fixed input and output !\n",
    "* Text is passed as numbers. Here, we used one-hot encoding, but there are plenty of other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
